{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OpoOWK6sGSo"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CwwlV59sGSr"
   },
   "source": [
    "# Lab 7.2.3: Stacking\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Read the guides and hints then create the necessary analysis and code to find an answer and conclusion for the scenario below.\n",
    "- The baseline results (minimum) are:\n",
    "    - **Accuracy** = 0.9667\n",
    "    - **ROC AUC**  = 0.9614\n",
    "- Try to achieve better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0w1VAuysGSt"
   },
   "source": [
    "# Foreword\n",
    "It is common that companies and professionals start with the data immediately available. Although this approach works, ideally the first step is to identify the problem or question and only then identify and obtain the set of data that can help to solve or answer the problem.\n",
    "\n",
    "Also, given the current abundance of data, processing power and some particular machine learning methods, there could be a temptation to use ALL the data available. **Quality** is _**better**_ than **Quantity**!\n",
    "\n",
    "Part of calling this discipline **Data Science** is that it is supposed to follow a process and not reach conclusions without support from evidence.\n",
    "\n",
    "Moreover, it is a creative, exploratory, laborious and iterative process. It is part of the process to repeat, review and change when finding a dead-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbBuCjV8sGSw"
   },
   "source": [
    "## Scenario: Predicting Breast Cancer\n",
    "The dataset you are going to be using for this laboratory is popularly known as the **Wisconsin Breast Cancer** dataset (`breast-cancer-wisconsin-data-old.csv`). The task related to it is Classification.\n",
    "\n",
    "The dataset contains a total number of _10_ features labelled in either **benign** or **malignant** classes. The features have _699_ instances out of which _16_ feature values are missing. The dataset only contains numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDlYwu8FsGSz"
   },
   "source": [
    "# Step 1: Define the problem or question\n",
    "Identify the subject matter and the given or obvious questions that would be relevant in the field.\n",
    "\n",
    "## Potential Questions\n",
    "List the given or obvious questions.\n",
    "\n",
    "## Actual Question\n",
    "Choose the **one** question that should be answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Can we predict whether a breast mass is benign or malignant based on the given features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7tXdNdvsGS1"
   },
   "source": [
    "# Step 2: Find the Data\n",
    "### Wisconsin Breast Cancer DataSet\n",
    "- **Citation Request**\n",
    "\n",
    "    This breast cancer databases was obtained from the **University of Wisconsin Hospitals**, **Madison** from **Dr. William H. Wolberg**. If you publish results when using this database, then please include this information in your acknowledgements.\n",
    "\n",
    "- **Title**\n",
    "\n",
    "    Wisconsin Breast Cancer Database (January 8, 1991)\n",
    "\n",
    "- **Sources**\n",
    "    - **Creator**\n",
    "            Dr. William H. Wolberg (physician)\n",
    "            University of Wisconsin Hospitals\n",
    "            Madison, Wisconsin\n",
    "            USA\n",
    "    - **Donor**\n",
    "            Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
    "            Received by David W. Aha (aha@cs.jhu.edu)\n",
    "    - **Date**\n",
    "            15 July 1992\n",
    "        \n",
    "### UCI - Machine Learning Repository\n",
    "- Center for Machine Learning and Intelligent Systems\n",
    "\n",
    "The [**UCI Machine Learning Repository**](http://archive.ics.uci.edu/about) is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk_JJ8xlsGS3"
   },
   "source": [
    "# Step 3: Read the Data\n",
    "- Read the data\n",
    "- Perform some basic structural cleaning to facilitate the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('breast-cancer-wisconsin-data-old.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTCAHTgLsGS5"
   },
   "source": [
    "# Step 4: Explore and Clean the Data\n",
    "- Perform some initial simple **EDA** (Exploratory Data Analysis)\n",
    "- Check for\n",
    "    - **Number of features**\n",
    "    - **Data types**\n",
    "    - **Domains, Intervals**\n",
    "    - **Outliers** (are they valid or spurious data [read or measure errors])\n",
    "    - **Null** (values not present or coded [as zero of empty strings])\n",
    "    - **Missing Values** (coded [as zero of empty strings] or values not present)\n",
    "    - **Coded content** (classes identified by numbers or codes to represent absence of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Sample_number                699 non-null    int64 \n",
      " 1   Clump_Thickness              699 non-null    int64 \n",
      " 2   Cell_Size_Uniformity         699 non-null    int64 \n",
      " 3   Cell_Shape_Uniformity        699 non-null    int64 \n",
      " 4   Marginal_Adhesion            699 non-null    int64 \n",
      " 5   Single_Epithelial_Cell_Size  699 non-null    int64 \n",
      " 6   Bare_Nuclei                  699 non-null    object\n",
      " 7   Bland_Chromatin              699 non-null    int64 \n",
      " 8   Normal_Nucleoli              699 non-null    int64 \n",
      " 9   Mitoses                      699 non-null    int64 \n",
      " 10  Class                        699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n",
      "None\n",
      "       Sample_number  Clump_Thickness  Cell_Size_Uniformity  \\\n",
      "count   6.990000e+02       699.000000            699.000000   \n",
      "mean    1.071704e+06         4.417740              3.134478   \n",
      "std     6.170957e+05         2.815741              3.051459   \n",
      "min     6.163400e+04         1.000000              1.000000   \n",
      "25%     8.706885e+05         2.000000              1.000000   \n",
      "50%     1.171710e+06         4.000000              1.000000   \n",
      "75%     1.238298e+06         6.000000              5.000000   \n",
      "max     1.345435e+07        10.000000             10.000000   \n",
      "\n",
      "       Cell_Shape_Uniformity  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
      "count             699.000000         699.000000                   699.000000   \n",
      "mean                3.207439           2.806867                     3.216023   \n",
      "std                 2.971913           2.855379                     2.214300   \n",
      "min                 1.000000           1.000000                     1.000000   \n",
      "25%                 1.000000           1.000000                     2.000000   \n",
      "50%                 1.000000           1.000000                     2.000000   \n",
      "75%                 5.000000           4.000000                     4.000000   \n",
      "max                10.000000          10.000000                    10.000000   \n",
      "\n",
      "       Bland_Chromatin  Normal_Nucleoli     Mitoses       Class  \n",
      "count       699.000000       699.000000  699.000000  699.000000  \n",
      "mean          3.437768         2.866953    1.589413    2.689557  \n",
      "std           2.438364         3.053634    1.715078    0.951273  \n",
      "min           1.000000         1.000000    1.000000    2.000000  \n",
      "25%           2.000000         1.000000    1.000000    2.000000  \n",
      "50%           3.000000         1.000000    1.000000    2.000000  \n",
      "75%           5.000000         4.000000    1.000000    4.000000  \n",
      "max          10.000000        10.000000   10.000000    4.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nU7e3BGsGS7"
   },
   "source": [
    "# Step 5: Prepare the Data\n",
    "- Deal with the data as required by the modelling technique\n",
    "    - **Outliers** (remove or adjust if possible or necessary)\n",
    "    - **Null** (remove or interpolate if possible or necessary)\n",
    "    - **Missing Values** (remove or interpolate if possible or necessary)\n",
    "    - **Coded content** (transform if possible or necessary [str to number or vice-versa])\n",
    "    - **Feature Engineer** (if useful or necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_number                  0\n",
      "Clump_Thickness                0\n",
      "Cell_Size_Uniformity           0\n",
      "Cell_Shape_Uniformity          0\n",
      "Marginal_Adhesion              0\n",
      "Single_Epithelial_Cell_Size    0\n",
      "Bare_Nuclei                    0\n",
      "Bland_Chromatin                0\n",
      "Normal_Nucleoli                0\n",
      "Mitoses                        0\n",
      "Class                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "# Convert 'Bare_Nuclei' to numeric\n",
    "data['Bare_Nuclei'] = pd.to_numeric(data['Bare_Nuclei'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHsn1Y_BsGS8"
   },
   "source": [
    "# Step 6: Modelling\n",
    "Refer to the Problem and Main Question.\n",
    "- What are the input variables (features)?\n",
    "- Is there an output variable (label)?\n",
    "- If there is an output variable:\n",
    "    - What is it?\n",
    "    - What is its type?\n",
    "- What type of Modelling is it?\n",
    "    - [ ] Supervised\n",
    "    - [ ] Unsupervised\n",
    "- What type of Modelling is it?\n",
    "    - [ ] Regression\n",
    "    - [ ] Classification (binary)\n",
    "    - [ ] Classification (multi-class)\n",
    "    - [ ] Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop(['Sample_number', 'Class'], axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNE4KKxrsGS-"
   },
   "source": [
    "# Step 7: Split the Data\n",
    "\n",
    "Need to check for **Supervised** modelling:\n",
    "- Number of known cases or observations\n",
    "- Define the split in Training/Test or Training/Validation/Test and their proportions\n",
    "- Check for unbalanced classes and how to keep or avoid it when splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAdSJL2IsGS_"
   },
   "source": [
    "# Step 8: Define and Fit Models\n",
    "\n",
    "Define the model and its hyper-parameters.\n",
    "\n",
    "Consider the parameters and hyper-parameters of each model at each (re)run and after checking the efficiency of a model against the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arfz_kGXsGTA"
   },
   "source": [
    "# Step 9: Verify and Evaluate the Training Model\n",
    "- Use the **training** data to make predictions\n",
    "- What metrics are appropriate for the modelling approach used\n",
    "- For **Supervised** models:\n",
    "    - Check the **Training Results** with the **Training Predictions** during development\n",
    "- Analyse, modify the parameters and hyper-parameters and repeat (within reason) until the model does not improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V738ZOusGTB"
   },
   "source": [
    "# Step 10: Make Predictions and Evaluate the Test Model\n",
    "**NOTE**: **Do this only after not making any more improvements in the model**.\n",
    "\n",
    "- Use the **test** data to make predictions\n",
    "- For **Supervised** models:\n",
    "    - Check the **Test Results** with the **Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    results[name] = {'Accuracy': accuracy, 'ROC AUC': roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az-R88PhsGTC"
   },
   "source": [
    "# Step 11: Solve the Problem or Answer the Question\n",
    "The results of an analysis or modelling can be used:\n",
    "- As part of a product or process, so the model can make predictions when new input data is available\n",
    "- As part of a report including text and charts to help understand the problem\n",
    "- As input for further questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "Random Forest:\n",
      "  Accuracy: 0.9571\n",
      "  ROC AUC:  0.9888\n",
      "Gradient Boosting:\n",
      "  Accuracy: 0.9500\n",
      "  ROC AUC:  0.9905\n",
      "SVM:\n",
      "  Accuracy: 0.9571\n",
      "  ROC AUC:  0.9894\n",
      "\n",
      "Best performing model: Gradient Boosting\n",
      "Accuracy: 0.9500\n",
      "ROC AUC:  0.9905\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Performance:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"  ROC AUC:  {metrics['ROC AUC']:.4f}\")\n",
    "\n",
    "best_model = max(results, key=lambda x: results[x]['ROC AUC'])\n",
    "print(f\"\\nBest performing model: {best_model}\")\n",
    "print(f\"Accuracy: {results[best_model]['Accuracy']:.4f}\")\n",
    "print(f\"ROC AUC:  {results[best_model]['ROC AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusion:\n",
      "Based on the analysis, we can predict whether a breast mass is benign or malignant\n",
      "with high accuracy using the given features. The best performing model achieves\n",
      "an accuracy of 0.9500 and an ROC AUC score of 0.9905,\n",
      "which exceeds the baseline results mentioned in the instructions.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConclusion:\")\n",
    "print(\"Based on the analysis, we can predict whether a breast mass is benign or malignant\")\n",
    "print(\"with high accuracy using the given features. The best performing model achieves\")\n",
    "print(f\"an accuracy of {results[best_model]['Accuracy']:.4f} and an ROC AUC score of {results[best_model]['ROC AUC']:.4f},\")\n",
    "print(\"which exceeds the baseline results mentioned in the instructions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2024 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
