{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Owk-_RSmVbQc"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Bf5LD7ZVbQd"
   },
   "source": [
    "# Lab 2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NTE-h8JVbQe"
   },
   "source": [
    "## Statistical Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVaASAlxVbQf"
   },
   "source": [
    "### Part 1: Student's t-Test\n",
    "\n",
    "The *t*-test is probably the most used statistical test. It measures the likelihood that a sample belongs to a given distribution, and incorporates a correction for the finite size of the sample.\n",
    "\n",
    "#### Using the t-test to compare two means\n",
    "\n",
    "Here, suppose we have two sets of measurements and we want to know if they both came from the same distribution.\n",
    "\n",
    "For example, in [this](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data) dataset these could be age of house in one group and median value of house in another group, and we are testing the null hypothesis that there is no difference between the two groups.\n",
    "\n",
    "#### Collect Data\n",
    "\n",
    "You can find the original data [here](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data).\n",
    "\n",
    "Data dictionary is available [here](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K1gDvR8WVbQf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tpDR7frKVbQi"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'housing.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRIM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINDUS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHAS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAGE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPTRATIO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMEDV\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhousing.data\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mnames, delim_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing.data'"
     ]
    }
   ],
   "source": [
    "names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
    "data = pd.read_csv(\"../../../DATA/housing.data\", header=None, names=names, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySJiFaU2VbQk"
   },
   "outputs": [],
   "source": [
    "# Head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0scc4_kVbQm"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuyPT527VbQo"
   },
   "source": [
    "##### 1. Plot Histogram of `RM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13SA_biyVbQp"
   },
   "outputs": [],
   "source": [
    "#  ANSWER\n",
    "RM = data['RM']\n",
    "RM.plot(kind='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhLlLDPYVbQr"
   },
   "source": [
    "##### 2. Plot Histogram of `MEDV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgDOrdZGVbQs"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "MEDV = data['MEDV']\n",
    "MEDV.plot(kind='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Gt-bOwoVbQu"
   },
   "source": [
    "##### 3.A Draw Scatter Plot of `RM` & `MEDV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5biDWDUcVbQu"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "sns.lmplot(x=\"RM\", y=\"MEDV\", data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RM'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtenHV2AVbQw"
   },
   "source": [
    "##### 3.B Is there any trend? State your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1Nsn8LVVbQx"
   },
   "source": [
    "**ANSWER:**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y03aU6p5VbQy"
   },
   "source": [
    "We'll be using following steps:\n",
    "\n",
    "- Define hypothesis\n",
    "- Set alpha (Let alpha = 0.05)\n",
    "- Calculate point estimate\n",
    "- Calculate test statistic\n",
    "- Find the p-value\n",
    "- Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOUCadVJVbQy"
   },
   "source": [
    "##### 4. Define Hypothesis\n",
    "\n",
    "Let's assume if `RM` of house is more than 6, it is a large house. Otherwise the house is small. Price of houses increases when the `RM` increases.\n",
    "\n",
    "**ANSWER:**\n",
    "\n",
    "    H0: There is no difference in the mean of prices between the large and small houses.\n",
    "    H1: There is a difference in the mean of prices between the large and small houses.\n",
    "    \n",
    "**[Note]** _If you want you can explore the dataset and define different hypothesis._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-enrQ2SVbQz"
   },
   "source": [
    "##### 5. Set alpha (Let alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHliQn5zVbQ0"
   },
   "source": [
    "First, we should specify our criterion for statistical significance. Traditionally, we allow for no more than a 1-in-20 chance of a spurious rejection of the null hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8aZM8buVbQ0"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQUl-zrRVbQ2"
   },
   "source": [
    "##### 6. Set Data\n",
    "\n",
    "Now, let's create two sets of data\n",
    "- Large House: Houses which have more than 6 rooms.\n",
    "- Small House: Houses which have no more than 6 rooms.\n",
    "\n",
    "Take sample of 100 houses in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AX-ycxPFVbQ3"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "N = 100\n",
    "medv_over_6 = data[data['RM'] > 6]['MEDV'].sample(N, random_state=10)\n",
    "medv_under_6 = data[data['RM'] <= 6]['MEDV'].sample(N, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyXzqCI3VbQ5"
   },
   "source": [
    "##### 6.A [BONUS] Build histogram for both `Large House` & `Small House`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USRdEfwzVbQ5"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "ax = sns.distplot(medv_over_6, label='Large House', kde=False);\n",
    "sns.distplot(medv_under_6, ax=ax, label='Small House', kde=False);\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms7hKNqwVbQ7"
   },
   "source": [
    "##### 7. Calculate Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_qyruX-VbQ8"
   },
   "source": [
    "Calculate variance for both samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8io49nQVbQ9"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "var_medv_over_6 = medv_over_6.var()\n",
    "print(var_medv_over_6)\n",
    "var_medv_under_6 = medv_under_6.var()\n",
    "print(var_medv_under_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddof should be 1\n",
    "np.var(medv_over_6, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be5deiNaVbQ_"
   },
   "source": [
    "##### 8. Calculate Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZTeLmbLVbQ_"
   },
   "source": [
    "\n",
    "Because we are dealing with two samples we need to compute the joint standard deviation.\n",
    "\n",
    "Here sp is the pooled standard deviation for n = n1 = n2 and s^2\n",
    "X1 and s^2 X2 are the unbiased estimators of the variances of the two samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-vBbtOBVbRA"
   },
   "source": [
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f63e99c30c01445668ea2cce9832da0f6810cb4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fj_T37yqVbRB"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "std = np.sqrt((var_medv_over_6 + var_medv_under_6) / 2)\n",
    "print('std dev:', std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i2iWoxDVbRD"
   },
   "source": [
    "##### 9. Calculate test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZXbRIJnVbRE"
   },
   "source": [
    "The *t*-statistic depends on the difference between the sample means and their joint standard deviation:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/070d365e1b347ea5f83f0147043868fa120b6646)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIlDIlpJVbRF"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "t = (medv_over_6.mean() - medv_under_6.mean()) / (std * np.sqrt(2 / N))  # t-statistic\n",
    "print('t:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwbh94u3VbRI"
   },
   "source": [
    "##### 10. Calculate Degree of Freedom\n",
    "\n",
    "The number of degrees of freedom is the total number of samples (here, this is N from each set) minus the number of statistics in the computation (1 for each sample mean):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAD7bJgDVbRJ"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "df = 2 * N - 2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11iYZzMwVbRO"
   },
   "source": [
    "##### 11. Find the p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0_VbRKjVbRP"
   },
   "source": [
    "Now we can compute the probability of the above *t*-statistic from the cumulative density function:\n",
    "\n",
    "> stats.t.cdf\n",
    "\n",
    "> p_value = 1 - cdf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufIYKyPtVbRR"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "p = 1 - stats.t.cdf(abs(t), df=df)  # #p-value after comparison with the t\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(2 * p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hLb8Ld3VbRU"
   },
   "source": [
    "#### Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVfad_eSVbRV"
   },
   "source": [
    "##### 12. Write a Function to Test Significance of `p_value`\n",
    "\n",
    "Write a function which will take p_value and alpha as input. If p_value < alpha, print reject null hypothesis message. Otherwise print a fail to reject null hypothesis message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0kBcmDKVbRV"
   },
   "outputs": [],
   "source": [
    "# Null Hypothesis Dictionary\n",
    "null_hypothesis = {\n",
    "    'H0': \"House price does not increase for large house.\"\n",
    "    , 'H1': \"House price increases for large house.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sig(p_value, alpha):\n",
    "    '''\n",
    "    Inputs:\n",
    "    p_value: Calculated p_value\n",
    "    alpha: Confidence level\n",
    "    '''\n",
    "    if p_value < alpha:\n",
    "        print(\"We reject our null hypothesis.\")\n",
    "        print(null_hypothesis['H1'])\n",
    "    elif p_value > alpha:\n",
    "        print(\"We fail to reject our null hypothesis.\")\n",
    "        print(null_hypothesis['H0'])\n",
    "    else:\n",
    "        print(\"Our test is inconclusive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fR1t5P69VbRZ"
   },
   "outputs": [],
   "source": [
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p*2))\n",
    "print_sig(p*2, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrs0gOXeVbRl"
   },
   "source": [
    "##### 13. [Bonus] Write a function to calculate t, p_value from two samples.\n",
    "\n",
    "Calculate the T-test for the means of *two independent* samples of scores.\n",
    "\n",
    "This is a two-sided test for the null hypothesis that 2 independent samples\n",
    "have identical average (expected) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mnan5sf_VbRm"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "def check_sig(p_value, alpha):\n",
    "    '''\n",
    "    Inputs:\n",
    "    p_value: Calculated p_value\n",
    "    alpha: Confidence level\n",
    "\n",
    "    Returns:\n",
    "    Significance message\n",
    "    '''\n",
    "\n",
    "    str_result = ''\n",
    "\n",
    "    if p_value < alpha:\n",
    "        str_result = \"We reject our null hypothesis.\"\n",
    "        str_result += '\\n'\n",
    "        str_result += null_hypothesis['H1']\n",
    "    elif p_value > alpha:\n",
    "        str_result = \"We fail to reject our null hypothesis.\"\n",
    "        str_result += '\\n'\n",
    "        str_result += null_hypothesis['H1']\n",
    "    else:\n",
    "        str_result = \"Our test is inconclusive.\"\n",
    "\n",
    "    return str_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_ind(a, b, alpha=0.05):\n",
    "    '''\n",
    "    a, b: The arrays must have the same shape\n",
    "    alpha: value of alpha\n",
    "    '''\n",
    "    N = len(a)\n",
    "\n",
    "    # Calculate Variance\n",
    "    var_a = a.var()\n",
    "    var_b = b.var()\n",
    "\n",
    "    # Calculate Standard Deviation\n",
    "    std = np.sqrt((var_a + var_b) / 2)\n",
    "\n",
    "    # Calculate t-stat\n",
    "    t = (a.mean() - b.mean()) / (std * np.sqrt(2 / N))  # t-statistic\n",
    "\n",
    "    # Calculate degree of freedom\n",
    "    df = 2 * N - 2\n",
    "\n",
    "    # Calculate p-value\n",
    "    p = 1 - stats.t.cdf(abs(t), df=df)  # #p-value after comparison with the t\n",
    "    # Two-tail\n",
    "    p = p * 2\n",
    "\n",
    "    return t, p, check_sig(p, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p, sig = ttest_ind(medv_over_6, medv_under_6, alpha)\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))\n",
    "print(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyNc67_FVbRn"
   },
   "source": [
    "#### Use `Stats` Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqAeZgizVbRo"
   },
   "source": [
    "##### 14. Calculate the T-test for the means of *two independent* samples of scores\n",
    "\n",
    "using following method of stats calculate the T-test for the means of two independent samples of scores.\n",
    "\n",
    "> ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJgti3wYVbRp"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "t2, p2 = stats.ttest_ind(medv_over_6, medv_under_6)\n",
    "print(\"t = \" + str(t2))\n",
    "print(\"p = \" + str(p2))\n",
    "print_sig(p2, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttzF17-GVbRq"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2024 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
